# Insert chapter 2 title here
#Regression and model validation - exercise 2

*Describe the work you have done this week and summarize your learning.*
Data wrangling step
Prepare data from original file 
R script is here: https://github.com/rsund/IODS-project/blob/master/data/create_learning2014.R
install.packages("dplyr")
install.packages("GGally")
install.packages("tidyverse")
##Reading data:
```{r readdata,echo=TRUE,results='hide',message=FALSE,warning=FALSE}
library(dplyr)
library (ggplot2)
library(readxl)
getwd()
learning2014 <- read_excel("data/learning2014.xlsx")
 View (learning2014)
 dim (learning2014)
 head (learning2014)
 str(learning2014)
```
Describle dataset: data includes seven variables: gender,age, attitude, deep, stra, surf, points.
In which
gender: M (Male), F (Female)
age:Age (in years) derived from the date of birth
attitude: Global attitude toward statistics
deep: average of score related to deep learning
stra: average of score related to deep learning
surf: average of score related to surface questions
points: Exam points
full data from this :https://www.mv.helsinki.fi/home/kvehkala/JYTmooc/JYTOPKYS3-data.txt

## Exploring data
```{r plot}
library(dplyr)
library (GGally)
library(ggplot2)
library(tidyverse)
library(psych)
pairs.panels (learning2014)
```
Each individual plot shows the relationship between the variable in the horizontal vs the vertical of the grid
 *gender* is the discrete variable so we just forcus on continous variables like: **age*, *attitude*, *deep*, *stra*, *surf*, *points*

For example: correlation between *age* and *attitude* = 0.02

The diagonal is showing a histogram of each variable and it can be seen on the graph that *point* and *attitude* has a strong correlation (*r* = **0.44**)

```{r fig2, fig.path="figures/", fig.dim=c(10,10), results='hide', message=FALSE}
library(GGally)
library(ggplot2)
# create a more advanced plot matrix with ggpairs()
ggpairs(learning2014, 
        mapping = aes(col = gender, alpha = 0.3), 
        lower = list(combo = wrap("facethist", bins = 20))
        )
```

The highest correlation is between *attitude* and *points*

```{r test for association between *attitude* and *points*}
cor.test(learning2014$attitude,learning2014$points)
```
results of correlation in the cor.test between *attitude* and *points* = **0.4365245 **
It means: *attitude* = 0 -> *points* 
Plot the correlation between *attitude* and *points* .
```{r plot association between attitude and points}
p1 <- ggplot(learning2014, aes(x = attitude, y = points))
p2 <- p1 + geom_point()
p3 <- p2 + geom_smooth(method = "lm")
p4 <- p3 + ggtitle("relation between attitude and points")
print (p4)
```


Let's fit a linear model to the data. Points are explained by attitude.
The equation for the model is
$$
Y_i = \alpha + \beta_1 X_i + \epsilon_i
$$
where Y represent points, X is attitude, $\alpha$ is constant, $\beta_1$ is regression
coefficient for attitude, and $\epsilon$ is a random term.


## Linear regression


Estimation of the model yields the following results:
```{r, results='asis'}
m1 <- lm(learning2014$points ~learning2014$attitude, data = learning2014)
results <- summary(m1)
knitr::kable(results$coefficients, digits=3, caption="Regression coefficients")
```

Intercept as well as attitude are statistically significant predictors. 
Coefficient of determination $R^2$ = `r results$r.squared` that is not particularly high.
Probably some more predictors could be added to the model.
